{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milkyway@Home Separation Application Testing\n",
    "\n",
    "Tom Donlon, RPI (2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm guessing that if you're reading this file, you're already (too) deeply involved in the Separation Application project. If that is the case, best of luck. In case that is not the situation, I've written a quick introduction to the project in the following paragraph. \n",
    "\n",
    "The Milkyway@home Separation Application is a decade-long project that spans over at least 5 different graduate students. The main goal of the application is to develop an algorithm that will separate out streams and other substructure from a background. This is done typically using Main Sequence Turnoff Stars (MSTO) and specific stream and background models. These models are fit to the data through optimization on Milkyway@home using the BOINC client. Read Jake Weiss' (and Nate Cole's, Matthew Newby's) thesis for more specific information. \n",
    "\n",
    "The separation application has been confirmed to succeed in recreating hand-made data, encouraging confidence in the application. However, this handmade data is typically optimal situations, and streams are rarely placed in unfortunate positions or unfortunate orientations within the generated data. For example, we do not understand what happens when you attempt to fit 3 streams to a data set with 4 streams, or vice versa. We do not understand what the optimized data looks like when streams are placed on the boundaries of the wedge (whether in distance or ra/dec). We have not incorporated different levels of noise into the tests. There are many other situations that need to be explored in order to better systematically understand what the optimizer does and \"thinks\" during these simulations, and what the real data may actually look like given certain strange output scenarios from the separation application. \n",
    "\n",
    "For these reasons, I believe it would be beneficial to have a stringent testing routine take place, where many different facets of the algorithm and application are explored. This will enable us to look at output of the separation optimizations and better understand what the optimizer is \"saying\", instead of tweaking parameters and just hoping that the output becomes more intuitive (like we do right now). Clearly an intuitive understanding of the application can only be gained through observing edge cases of the application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test wedges are generated using test_wedge_generator.py found at https://github.com/weissj3/Newby-tools. All of the required files can be found here as well. \n",
    "\n",
    "Test wedge files and the corresponding parameter files can be found at https://github.com/thomasdonlon/separation. \n",
    "\n",
    "Test wedges are then optimized on the Milkyway@home server. Testing on a personal client is STRONGLY RECOMMENDED before release onto the milkyway server.\n",
    "\n",
    "Results are typically subjective and are open to interpretation. The goal is to develop an understanding of interpreting the optimizer's output with regards to intuition, not necessarily building an objective way of analyzing the application. Discussion and analysis of each test will be provided in each test's subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bookkeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of tests is not set in stone. Tests may be added or subtracted as the testing project evolves. Tests that have been sufficiently explored will be marked here as such. Descriptions and results of each series of tests are provided below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Test | Run Names | Star Files | Parameter Files | Completed? |\n",
    "|----------|-------------:|--------:|--------:|--------:|\n",
    "| Underfitting # Streams | N/A | stars-4s-3f.txt | parameters-test-4s-3f.txt | N |\n",
    "| -- | -- | stars-4s-3f-2.txt | -- | -- |\n",
    "| -- | -- | stars-4s-3f-3.txt | -- | -- |\n",
    "| Overfitting # Streams | N/A | N/A | N/A | N |\n",
    "| Streams on Edges | N/A | N/A | N/A | N |\n",
    "| Signal-to-Noise Limitations | N/A | N/A | N/A | N |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting # of Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to run the first trials with 3 runs per test. If more/fewer seem appropriate, we can adjust that in the future.\n",
    "\n",
    "Stream parameters are more or less randomly generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star File Generation Parameters: (stars-4s-3f.txt) (4 streams, 3 fit)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = twg.ParamSet()\n",
    "params.wedge = 14\n",
    "params.background = [0.9965, 1.0, 0.56, 8.0, 1.0]\n",
    "params.streams = [ [-0.5, 183.946, 28.5, 135., 120., 4.0],\n",
    "                   [-1.0, 213.341, 25., 50., 75., 2.0],\n",
    "                   [-1.5, 222.128, 35., 190., 55., 3.0],\n",
    "                   [-2.0, 153.657, 13., 75., 20., 5.0]\n",
    "                   ]\n",
    "params.stripe = [(135.0, 235.0, 10), (-1.25, 1.25, 10), (16.0, 22.5, 10)]\n",
    "params.update_refs()\n",
    "twg.build_stripe(params, filename=\"stars-4s-3f.txt\", num_stars=25000,\n",
    "    perturb_weight=0., perturb_params=(0.0, 0.79, -19.9), con=1, det=1, app=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star file generation parameters: (stars-4s-3f-2.txt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params.wedge = 14\n",
    "params.background = [0.9965, 1.0, 0.56, 8.0, 1.0]\n",
    "params.streams = [ [-0.1, 149., 31, 98., 45., 3.0],\n",
    "                   [-2.5, 147., 12., 302., 88., 10.0],\n",
    "                   [-1.2, 189., 9., 163., 59., 2.0],\n",
    "                   [-2.5, 205., 16., 301., 173., 4.0]\n",
    "                   ]\n",
    "params.stripe = [(135.0, 235.0, 10), (-1.25, 1.25, 10), (16.0, 22.5, 10)]\n",
    "params.update_refs()\n",
    "twg.build_stripe(params, filename=\"stars-4s-3f-2.txt\", num_stars=25000,\n",
    "    perturb_weight=0., perturb_params=(0.0, 0.79, -19.9), con=1, det=1, app=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star file generation parameters: (stars-4s-3f-3.txt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params.wedge = 14\n",
    "params.background = [0.9965, 1.0, 0.56, 8.0, 1.0]\n",
    "params.streams = [ [-0.8, 177., 26., 342., 183., 10.0],\n",
    "                   [-1.5, 212., 37., 99., 15., 3.0],\n",
    "                   [-1.8, 180., 25., 298., 81., 4.0],\n",
    "                   [-0.6, 152., 33., 352., 133., 7.0]\n",
    "                   ]\n",
    "params.stripe = [(135.0, 235.0, 10), (-1.25, 1.25, 10), (16.0, 22.5, 10)]\n",
    "params.update_refs()\n",
    "twg.build_stripe(params, filename=\"stars-4s-3f-3.txt\", num_stars=25000,\n",
    "    perturb_weight=0., perturb_params=(0.0, 0.79, -19.9), con=1, det=1, app=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
